{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-Gram Language Model: Training and Text Generation\n",
    "\n",
    "This notebook demonstrates n-gram language modeling on the extended headlines dataset (10,000 headlines).\n",
    "\n",
    "## What is an N-Gram Language Model?\n",
    "\n",
    "An n-gram model predicts the next word based on the previous (n-1) words:\n",
    "\n",
    "**P(word | context) = Count(context, word) / Count(context)**\n",
    "\n",
    "For a 5-gram model:\n",
    "- Context = 4 previous words\n",
    "- Model predicts the 5th word\n",
    "- Example: Given `president announces new reform`, predict the next word\n",
    "\n",
    "## Key Concepts:\n",
    "1. **Smoothing**: Add-k smoothing handles unseen n-grams\n",
    "2. **Backoff**: If 5-gram not found, use 4-gram, then 3-gram, etc.\n",
    "3. **Generation**: Sample words based on conditional probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from ngram_model import NGramModel\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../extended/news_headlines_extended.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Total headlines: {len(df):,}\")\n",
    "print(f\"\\nCategory distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nFirst 5 headlines:\")\n",
    "print(df[['headline', 'category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = df['headline'].tolist()\n",
    "\n",
    "print(f\"Sample headlines:\")\n",
    "for i, headline in enumerate(headlines[:10], 1):\n",
    "    print(f\"{i:2d}. {headline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train 5-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training 5-gram model...\\n\")\n",
    "\n",
    "model = NGramModel(n=5, smoothing_k=0.01)\n",
    "model.train(headlines, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = model.get_ngram_stats()\n",
    "\n",
    "print(\"Model Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key:20s}: {value:,}\" if isinstance(value, int) else f\"{key:20s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Top N-Grams Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ngrams = model.get_top_ngrams(k=30)\n",
    "\n",
    "print(\"Top 30 Most Frequent 5-Grams:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<6} {'Context (4 words)':<50} {'Next Word':<15} {'Count':<6}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, (context, word, count) in enumerate(top_ngrams, 1):\n",
    "    context_str = ' '.join(context)\n",
    "    print(f\"{i:<6} {context_str:<50} {word:<15} {count:<6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization: N-Gram Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_counts = [count for _, _, count in top_ngrams]\n",
    "ranks = list(range(1, len(ngram_counts) + 1))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].bar(ranks, ngram_counts, color='steelblue', alpha=0.7)\n",
    "axes[0].set_xlabel('Rank', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Top 30 5-Gram Frequencies', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1].loglog(ranks, ngram_counts, 'o-', markersize=6, color='steelblue', alpha=0.7)\n",
    "axes[1].set_xlabel('Rank (log scale)', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency (log scale)', fontsize=12)\n",
    "axes[1].set_title('5-Gram Frequency (Log-Log)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conditional Probability Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_contexts = [\n",
    "    ('president', 'announces', 'new', 'reform'),\n",
    "    ('team', 'wins', 'championship', 'after'),\n",
    "    ('company', 'launches', 'new', 'device'),\n",
    "    ('million', 'for', 'new', 'technology'),\n",
    "    ('<start>', '<start>', '<start>', '<start>'),\n",
    "]\n",
    "\n",
    "print(\"Conditional Probability Examples:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for context in sample_contexts:\n",
    "    if context in model.ngrams:\n",
    "        print(f\"\\nContext: {' '.join(context)}\")\n",
    "        word_probs = [(word, model._get_probability(context, word))\n",
    "                     for word in model.ngrams[context].keys()]\n",
    "        word_probs.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"  Top 5 most likely next words:\")\n",
    "        for word, prob in word_probs[:5]:\n",
    "            print(f\"    P({word:15s} | context) = {prob:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\nContext: {' '.join(context)}\")\n",
    "        print(\"  Context not found in model (will use backoff)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Text Generation: Multiple Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating text samples...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\n--- Sample {i+1} (50 words) ---\\n\")\n",
    "    generated = model.generate(max_words=50)\n",
    "    print(generated)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Half a Page (~200 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating longer text (half a page, ~200 words)...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "long_text = model.generate(max_words=200)\n",
    "word_count = len(long_text.split())\n",
    "\n",
    "print(f\"[Generated {word_count} words]\\n\")\n",
    "print(long_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate with Seed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [\n",
    "    \"president announces new reform\",\n",
    "    \"team wins championship after\",\n",
    "    \"company launches new device\"\n",
    "]\n",
    "\n",
    "print(\"Text Generation with Seed Phrases:\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\nSeed: '{seed}'\\n\")\n",
    "    generated = model.generate(max_words=50, seed=seed)\n",
    "    print(generated)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Comparison: Different N-Gram Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training models with different n-gram sizes...\\n\")\n",
    "\n",
    "models = {}\n",
    "for n in [3, 4, 5]:\n",
    "    print(f\"Training {n}-gram model...\")\n",
    "    m = NGramModel(n=n, smoothing_k=0.01)\n",
    "    m.train(headlines, verbose=False)\n",
    "    models[n] = m\n",
    "    print(f\"  Vocabulary: {m.vocab_size}, Contexts: {len(m.ngrams)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Comparison of Generated Text (50 words each)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for n in [3, 4, 5]:\n",
    "    print(f\"\\n--- {n}-gram model ---\\n\")\n",
    "    generated = models[n].generate(max_words=50)\n",
    "    print(generated)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = 'models/5gram_extended.pkl'\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "model.save(model_path)\n",
    "print(f\"\\nModel successfully saved!\")\n",
    "print(f\"You can load it later using: model = NGramModel.load('{model_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Characteristics**:\n",
    "   - 5-gram model captures local context (4 previous words)\n",
    "   - Vocabulary size reflects the extended dataset\n",
    "   - Add-k smoothing handles unseen n-grams\n",
    "\n",
    "2. **Text Generation Quality**:\n",
    "   - Higher n (more context) produces more coherent text\n",
    "   - 5-gram model maintains better local structure than 3-gram\n",
    "   - Generated text follows the pattern of news headlines\n",
    "\n",
    "3. **Limitations**:\n",
    "   - Template-based training data creates repetitive patterns\n",
    "   - No long-range dependencies (only local context)\n",
    "   - May generate grammatically incorrect or semantically odd sequences\n",
    "\n",
    "4. **Applications**:\n",
    "   - Text completion and suggestion\n",
    "   - Spelling correction\n",
    "   - Baseline for more complex language models\n",
    "   - Educational tool for understanding language modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
